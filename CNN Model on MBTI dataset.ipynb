{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence, text\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Embedding, LSTM\n",
    "from keras.layers import Conv1D, Flatten, MaxPooling1D\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the Hyperparameters\n",
    "These will be required for building the neural network. We can play around with these and they will largely affect the accuracy of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 1000\n",
    "max_len =1000\n",
    "batch_size = 32\n",
    "embedding_dims =10\n",
    "filters = 16\n",
    "ker_size = 3 # kernel size\n",
    "hidden_dims = 250\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the Dataset from CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('mbti_cleaned.csv')\n",
    "data.dropna(inplace=True)  # ignoring the NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot encoding on the dataset output classes \n",
    "y = pd.DataFrame(data[['Is E','Is S','Is T', 'Is J']])\n",
    "x_train,x_test,y_train,y_test = train_test_split(data['Posts'], y,random_state=0)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = text.Tokenizer(num_words=vocab_size)\n",
    "tokenizer.fit_on_texts(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tokenizer.texts_to_matrix(x_train)\n",
    "x_test = tokenizer.texts_to_matrix(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = sequence.pad_sequences(x_train,maxlen=max_len)\n",
    "x_test = sequence.pad_sequences(x_test,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Sequential Neural Network using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# First we add an embedding layer \n",
    "model.add(Embedding(vocab_size,embedding_dims,input_length=max_len)) \n",
    "# Adding a 1D convolutional Layer\n",
    "model.add(Conv1D(filters, ker_size, padding='valid', activation='relu'))\n",
    "# Max Pooling the Convolutions\n",
    "model.add(MaxPooling1D())\n",
    "# Again Computing the Convolutions\n",
    "model.add(Flatten())\n",
    "model.add(Dense(hidden_dims, activation='relu'))\n",
    "model.add(Dense(4, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6471 samples, validate on 2157 samples\n",
      "Epoch 1/5\n",
      "6471/6471 [==============================] - 12s 2ms/step - loss: 0.5496 - acc: 0.7228 - val_loss: 0.4991 - val_acc: 0.7594\n",
      "Epoch 2/5\n",
      "6471/6471 [==============================] - 11s 2ms/step - loss: 0.4533 - acc: 0.7854 - val_loss: 0.4756 - val_acc: 0.7729\n",
      "Epoch 3/5\n",
      "6471/6471 [==============================] - 12s 2ms/step - loss: 0.4022 - acc: 0.8147 - val_loss: 0.4713 - val_acc: 0.7774\n",
      "Epoch 4/5\n",
      "6471/6471 [==============================] - 12s 2ms/step - loss: 0.3650 - acc: 0.8334 - val_loss: 0.4924 - val_acc: 0.7714\n",
      "Epoch 5/5\n",
      "6471/6471 [==============================] - 12s 2ms/step - loss: 0.3288 - acc: 0.8552 - val_loss: 0.5321 - val_acc: 0.7694\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25591060ba8>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the modeL\n",
    "model.fit(x_train,y_train, batch_size=batch_size, epochs=5, validation_data=(x_test, y_test),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Performance of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2157/2157 [==============================] - 0s 199us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "76.93555865732121"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test)[1]*100  # Accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2157/2157 [==============================] - 0s 205us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "76.93555865732121"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test)[1]*100  # Accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model into a pickle file \n",
    "import pickle\n",
    "pickle.dump(model,open('cnn_model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(tokenizer,open('tokenizer','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Single Input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "s ='Idealistic, loyal to their values and to people who are important to them. Want an external life that is congruent with their values. Curious, quick to see possibilities, can be catalysts for implementing ideas. Seek to understand people and to help them fulfill their potential. Adaptable, flexible, and accepting unless a value is threatened.'\n",
    "s = pd.Series(s)\n",
    "s= tokenizer.texts_to_matrix(s)\n",
    "s = sequence.pad_sequences(s)\n",
    "l = model.predict(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b= l[0][0]*(1/1999), l[0][1]*(1/1197)\n",
    "a = a/(1/1999)+(1/1197)\n",
    "b = b/(1/1999)+(1/1197)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [a,b,l[0][2],l[0][3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Personality is: INTP\n"
     ]
    }
   ],
   "source": [
    "s=''\n",
    "if l[0] >0.5:\n",
    "    s +='E'\n",
    "else:\n",
    "    s+='I'\n",
    "if l[1] >0.5:\n",
    "    s+='S'\n",
    "else:\n",
    "    s+='N'\n",
    "if l[2] >0.5:\n",
    "    s+='T'\n",
    "else:\n",
    "    s+='F'\n",
    "if l[3] >0.5:\n",
    "    s+='J'\n",
    "else:\n",
    "    s+='P'\n",
    "print('Your Personality is:',s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
